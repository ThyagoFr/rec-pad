{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "applied-summer",
   "metadata": {},
   "source": [
    "# Introdução ao Reconhecimento de Padrões, 2020.2, UFC/DETI\n",
    "## Trabalho 3\n",
    "\n",
    "Aluno : Thyago Freitas da Silva <br>\n",
    "Matrícula : 392035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "provincial-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import collections\n",
    "import pandas\n",
    "from random import randrange\n",
    "from sklearn.metrics import confusion_matrix as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-correspondence",
   "metadata": {},
   "source": [
    "### Scatter matrix helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(data):\n",
    "    return np.mean(np.array(data),axis=0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-technology",
   "metadata": {},
   "source": [
    "### Implementacão do classificador \"K-Means\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extensive-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_p = lambda x,y,p : abs((x-y))**p\n",
    "euclidian = lambda list1,list2: np.sqrt(sum(map(norm_p,list1,list2,[2]*len(list1))))\n",
    "\n",
    "class KMeansClassifier:\n",
    "    def __init__(self, K, R):\n",
    "        self.K = K\n",
    "        self.R = R\n",
    "        self.centroids = []\n",
    "    def fit_predict(self, x_train):\n",
    "        n = x_train.shape[0]\n",
    "        result = [0]*n\n",
    "        old = [0]*n\n",
    "        aux = 0\n",
    "        stop = False\n",
    "        idx = np.random.choice(len(x_train), self.K, replace=False)\n",
    "        for i in idx:\n",
    "            self.centroids.append(x_train.iloc[i,:].to_list())\n",
    "        while aux < self.R or stop:\n",
    "            for row in range(n):\n",
    "                d = []\n",
    "                for c in range(self.K):\n",
    "                    d.append(euclidian(x_train.iloc[row,:].to_list(),self.centroids[c]))\n",
    "                result[row] = (d.index(min(d)))\n",
    "            old = result[:]\n",
    "            changes = self.K\n",
    "            for c_n, c in enumerate(self.centroids):\n",
    "                values = []\n",
    "                values.append(c)\n",
    "                for index, r in enumerate(result):\n",
    "                    if r == c_n:\n",
    "                        values.append(x_train.iloc[index,:].to_list())\n",
    "                self.centroids[c_n] = self.calc_mean(values)\n",
    "            if aux != 0:\n",
    "                for v1,v2 in zip(old,result):\n",
    "                    if v1!=v2:\n",
    "                        stop = False\n",
    "            aux += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-davis",
   "metadata": {},
   "source": [
    "### Scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_cluster(data):\n",
    "    return \"resposta\"\n",
    "\n",
    "\n",
    "def between_cluster(data):\n",
    "    return \"resposta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-message",
   "metadata": {},
   "source": [
    "### Leitura da base \"demartology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rural-plane",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 366 entries, 0 to 365\n",
      "Data columns (total 35 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       366 non-null    int64 \n",
      " 1   1       366 non-null    int64 \n",
      " 2   2       366 non-null    int64 \n",
      " 3   3       366 non-null    int64 \n",
      " 4   4       366 non-null    int64 \n",
      " 5   5       366 non-null    int64 \n",
      " 6   6       366 non-null    int64 \n",
      " 7   7       366 non-null    int64 \n",
      " 8   8       366 non-null    int64 \n",
      " 9   9       366 non-null    int64 \n",
      " 10  10      366 non-null    int64 \n",
      " 11  11      366 non-null    int64 \n",
      " 12  12      366 non-null    int64 \n",
      " 13  13      366 non-null    int64 \n",
      " 14  14      366 non-null    int64 \n",
      " 15  15      366 non-null    int64 \n",
      " 16  16      366 non-null    int64 \n",
      " 17  17      366 non-null    int64 \n",
      " 18  18      366 non-null    int64 \n",
      " 19  19      366 non-null    int64 \n",
      " 20  20      366 non-null    int64 \n",
      " 21  21      366 non-null    int64 \n",
      " 22  22      366 non-null    int64 \n",
      " 23  23      366 non-null    int64 \n",
      " 24  24      366 non-null    int64 \n",
      " 25  25      366 non-null    int64 \n",
      " 26  26      366 non-null    int64 \n",
      " 27  27      366 non-null    int64 \n",
      " 28  28      366 non-null    int64 \n",
      " 29  29      366 non-null    int64 \n",
      " 30  30      366 non-null    int64 \n",
      " 31  31      366 non-null    int64 \n",
      " 32  32      366 non-null    int64 \n",
      " 33  33      366 non-null    object\n",
      " 34  34      366 non-null    int64 \n",
      "dtypes: int64(34), object(1)\n",
      "memory usage: 100.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pandas.read_csv(\"./data/dermatology.csv\", header=None)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-eleven",
   "metadata": {},
   "source": [
    "#### Pre-processamento\n",
    "\n",
    "Olhando o conteúdo do arquivo, foi notado que algumas linhas da coluna 33 (band-like infiltrate) apresentam valores marcados com \"?\" que atrapalham o resultado do algoritmo. Para remediar esse problema , decidi trocar os valores faltantes demarcados por \"?\" pela mediana da coluna 33, pois tal medida é menos sensível a outliers se comparado com a média, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "weird-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_median(array):\n",
    "    values = []\n",
    "    for v in array:\n",
    "        if v != '?':\n",
    "            v = int(v)\n",
    "            values.append(v)\n",
    "    return np.median(values)\n",
    "\n",
    "median = calc_median(data.iloc[:,33])\n",
    "data.iloc[:,33] = list(map(lambda value: median if value == '?' else value, data.iloc[:,33]))\n",
    "data.iloc[:,33] = data.iloc[:,33].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-davis",
   "metadata": {},
   "source": [
    "#### Normalizar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frozen-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    columns = data.shape[1] - 1 #subtrai 1 para descartar coluna com classes\n",
    "    for c in range(columns):\n",
    "        min_v = np.min(data.iloc[:,c])\n",
    "        max_v = np.max(data.iloc[:,c])\n",
    "        data.iloc[:,c] = data.iloc[:,c].apply(lambda v : (v - min_v)/(max_v - min_v))\n",
    "    return data\n",
    "\n",
    "data = normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-reproduction",
   "metadata": {},
   "source": [
    "#### Separar dados em atributos e classes de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "frozen-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributes = data.iloc[:,:34]\n",
    "target = data.iloc[:,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wanted-passing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeansClassifier(5,5)\n",
    "predict = kmeans.fit_predict(atributes)\n",
    "predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
