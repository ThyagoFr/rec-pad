{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "virgin-slovakia",
   "metadata": {},
   "source": [
    "# Introdução ao Reconhecimento de Padrões, 2020.2, UFC/DETI\n",
    "## Trabalho 1\n",
    "\n",
    "Aluno : Thyago Freitas da Silva <br>\n",
    "Matrícula : 392035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "knowing-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import collections\n",
    "import pandas as pd\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-theology",
   "metadata": {},
   "source": [
    "### Funções úteis durante o decorrer do relatório"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-timing",
   "metadata": {},
   "source": [
    "#### Transformar coluna contendo valores inválidos, substituindo-os pela mediana da coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "expanded-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_column(column):\n",
    "    transformed_column = np.array([0]*len(column))\n",
    "    values = []\n",
    "    for v in column:\n",
    "        if v != '?':\n",
    "            v = float(v)\n",
    "            values.append(v)\n",
    "    median = np.median(values)\n",
    "    for index in range(len(column)):\n",
    "        if column[index] == '?':\n",
    "            transformed_column[index] = median\n",
    "        else:\n",
    "            transformed_column[index] = float(column[index])\n",
    "    return transformed_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-nancy",
   "metadata": {},
   "source": [
    "#### Calcular acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "enormous-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(prediction,real_values):\n",
    "    size = len(real_values)\n",
    "    corrects = 0\n",
    "    for index in range(size):\n",
    "        if prediction[index] == real_values[index]:\n",
    "            corrects += 1\n",
    "    return corrects/size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-combining",
   "metadata": {},
   "source": [
    "#### Calcular acurácia por classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "national-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_per_class(prediction,real_values,classe):\n",
    "    size = len(real_values)\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    for index in range(size):\n",
    "        if real_values[index] == classe:\n",
    "            total += 1\n",
    "        if prediction[index] == real_values[index] == classe:\n",
    "            corrects += 1\n",
    "    return corrects/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-adjustment",
   "metadata": {},
   "source": [
    "#### Calcular matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "optimum-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predict,real_values):\n",
    "    classes = set(real_values)\n",
    "    n_predicts = len(predict)\n",
    "    n_classes = len(classes)\n",
    "    confusion_m = np.zeros((n_classes,n_classes))\n",
    "    for cl in classes:\n",
    "        for index in range(n_predicts):\n",
    "            if real_values[index] == cl:\n",
    "                confusion_m[int(predict[index])-1,int(real_values[index])-1] += 1\n",
    "    return confusion_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-insured",
   "metadata": {},
   "source": [
    "#### Calcular o discriminante para o LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "beautiful-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrimant(mean_per_class,within_classes,new_data,classes,class_value,n_features):\n",
    "    count_instances = np.count_nonzero(classes == class_value)\n",
    "    first_term = np.dot(mean_per_class,np.linalg.inv(within_classes))\n",
    "    mul_transpose = np.dot(first_term,new_data)\n",
    "    second_term = np.dot(0.5*first_term,np.transpose(mean_per_class))\n",
    "    return mul_transpose - second_term + np.log(count_instances/n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-macedonia",
   "metadata": {},
   "source": [
    "#### Calcular matriz de espalhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "comprehensive-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_classes(features,cov_matrixes,classes):\n",
    "    dim = features.shape[1]\n",
    "    rows = features.shape[0]\n",
    "    w_c = np.zeros((dim,dim))\n",
    "    values = []\n",
    "    for cov_idx,cov in enumerate(cov_matrixes):\n",
    "        n_instances_of_class = np.count_nonzero(classes == cov_idx)\n",
    "        term = (n_instances_of_class/rows)*cov\n",
    "        values.append(term)\n",
    "    for v in values:\n",
    "        w_c = np.add(w_c,v)\n",
    "    return w_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-happening",
   "metadata": {},
   "source": [
    "#### Matriz de covariância para uma classe específica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "technological-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_matrix(features,classes,class_value,mean):\n",
    "    columns = features.shape[1]\n",
    "    rows = classes == class_value\n",
    "    matriz = features[rows]\n",
    "    for row in matriz:\n",
    "        for c in range(columns):\n",
    "            row[c] -= mean[c]\n",
    "    n_instances_of_class = np.count_nonzero(classes == class_value)\n",
    "    cov = (1/n_instances_of_class)*np.dot(np.transpose(matriz),matriz)\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-details",
   "metadata": {},
   "source": [
    "#### Calcular o vetor médiro de uma matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "human-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_mean(features):\n",
    "    return np.mean(features, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-california",
   "metadata": {},
   "source": [
    "## Parte 0 : Banco de dados - Demartology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-ticket",
   "metadata": {},
   "source": [
    "O banco de dados utilizado foi o \"Demartology\" que possui as seguintes características:\n",
    "\n",
    "<ul>\n",
    "<li>O arquivo CSV com os dados possui 35 colunas, sendo que a última coluna representa de forma numérica uma doenção demartológica.</li>\n",
    "<li>A coluna 33 (band-like infiltrate) apresenta valores inválidos e que precisam ser removidos ou processados.</li>\n",
    "<li>Temos 366 amostras no banco de dados.</li>\n",
    "<li>A coluna 34 representa uma doença demartológica de forma numérica(1 à 6), sendo elas :</li>\n",
    "    <ol>\n",
    "        <li>psoriasis</li>\n",
    "        <li>seboreic dermatitis</li>\n",
    "        <li>lichen planus</li>\n",
    "        <li>pityriasis rosea</li>\n",
    "        <li>cronic dermatitis</li>\n",
    "        <li>pityriasis rubra pilaris</li>\n",
    "    </ol>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "urban-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  25  26  27  28  29  30  31  \\\n",
       "0   2   2   0   3   0   0   0   0   1   0  ...   0   0   3   0   0   0   1   \n",
       "1   3   3   3   2   1   0   0   0   1   1  ...   0   0   0   0   0   0   1   \n",
       "2   2   1   2   3   1   3   0   3   0   0  ...   0   2   3   2   0   0   2   \n",
       "3   2   2   2   0   0   0   0   0   3   2  ...   3   0   0   0   0   0   3   \n",
       "4   2   3   2   2   2   2   0   2   0   0  ...   2   3   2   3   0   0   2   \n",
       "\n",
       "   32  33  34  \n",
       "0   0  55   2  \n",
       "1   0   8   1  \n",
       "2   3  26   3  \n",
       "3   0  40   1  \n",
       "4   3  45   3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv(\"./data/dermatology.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-special",
   "metadata": {},
   "source": [
    "## Parte 1 : KNearest Neighbors\n",
    "### Funcionamento do algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-involvement",
   "metadata": {},
   "source": [
    "O algoritmo conhecido como KNN (K-Nearest Neighbors) é um dos muitos algoritmos para classificação, mas que também possui uma versão que pode ser utilizada para regressão, e um dos primeiros a serem apresentados a iniciantes na área de aprendizado de máquina. Seu funcionamento pode ser descrito nas seguintes etapas.\n",
    "\n",
    "<ol>\n",
    "<li>Recebe uma amostra que ainda não foi classificada.</li>\n",
    "<li>Calcula a distância dessa amostra para todas as outras amostras do banco de dados(a métrica utilizada para calcular a distância pode variar com base nos cenários de projeto.).</li>\n",
    "<li>Filtra as K amostras mais próximas da amostra não classificada ainda.</li>\n",
    "<li>Verifica a classe mais frequentes dentre as K amostras filtradas no passo 3.</li>\n",
    "<li>Classifica a amostra do passo 1 como pertencente a classe obtida no passo 4.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-proof",
   "metadata": {},
   "source": [
    "### Implementacão do classificador \"K-Nearest Neighbors (KNN)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "failing-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_p = lambda x,y,p : abs((x-y))**p\n",
    "euclidian = lambda list1,list2: np.sqrt(sum(map(norm_p,list1,list2,[2]*len(list1))))\n",
    "manhatan = lambda list1,list2: sum(map(norm_p,list1,list2,[1]*len(list1)))\n",
    "\n",
    "metrics = {\n",
    "    \"euclidian\" : euclidian,\n",
    "    \"manhatan\" : manhatan\n",
    "}\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, metric=\"euclidian\", n_neighbors=3):\n",
    "        if metric not in metrics:\n",
    "            message = \"invalid metric. the acceptable values are :\"\n",
    "            for k in metrics.keys():\n",
    "                message += \" \" + k\n",
    "            raise Exception(message)\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric_name = metric\n",
    "        self.metric_func = metrics[metric]\n",
    "    def fit(self, x_train,y_train):\n",
    "        if len(x_train) != len(y_train):\n",
    "            raise Exception(\"the size of inputs must be equals\")\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def predict(self,x_test):\n",
    "        distances = []\n",
    "        result = []\n",
    "        for test in x_test:\n",
    "            for index in range(len(self.x_train)):\n",
    "                distance = self.metric_func(self.x_train[index],test)\n",
    "                distances.append((self.y_train[index], distance))\n",
    "            distances = sorted(distances, key = lambda tup : tup[1])\n",
    "            classes = collections.Counter(map(lambda x : x[0], distances[:self.n_neighbors]))\n",
    "            clas = classes.most_common(1)\n",
    "            result.append(clas[0][0])\n",
    "            distances.clear()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-ambassador",
   "metadata": {},
   "source": [
    "## Parte 1.1 : KNearest Neighbors\n",
    "### Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-broadcast",
   "metadata": {},
   "source": [
    "#### Leitura da base \"demartology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fixed-lithuania",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  25  26  27  28  29  30  31  \\\n",
       "0   2   2   0   3   0   0   0   0   1   0  ...   0   0   3   0   0   0   1   \n",
       "1   3   3   3   2   1   0   0   0   1   1  ...   0   0   0   0   0   0   1   \n",
       "2   2   1   2   3   1   3   0   3   0   0  ...   0   2   3   2   0   0   2   \n",
       "3   2   2   2   0   0   0   0   0   3   2  ...   3   0   0   0   0   0   3   \n",
       "4   2   3   2   2   2   2   0   2   0   0  ...   2   3   2   3   0   0   2   \n",
       "\n",
       "   32  33  34  \n",
       "0   0  55   2  \n",
       "1   0   8   1  \n",
       "2   3  26   3  \n",
       "3   0  40   1  \n",
       "4   3  45   3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv(\"./data/dermatology.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-madison",
   "metadata": {},
   "source": [
    "Converter o dataframe pandas para um objeto do numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "durable-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-wonder",
   "metadata": {},
   "source": [
    "#### Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-danish",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Como informado anteriormente, a coluna 33 do banco de dados possui valores inválidos que atrapalham a execução do algoritmo, logo, afim de evitar a remoção da amostras que possuem esse problema, foi adotado a heurística de substituir os valores inválidos,pontos de interrogação,pela mediana da coluna. A mediana foi escolhida por ser menos sensível a outliers se comparada com a média, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "individual-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:,33] = transform_column(data[:,33])\n",
    "data = data.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-logistics",
   "metadata": {},
   "source": [
    "Agora iremos separar o conjunto de dados em uma matriz de features e um array com as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "necessary-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[:,:34]\n",
    "classes = data[:,34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-benchmark",
   "metadata": {},
   "source": [
    "#### Execução do algoritmo (usando a distância EUCLIDIANA):\n",
    "\n",
    "<ul>\n",
    "    <li> Utilizando K = 7 </li>\n",
    "    <li> Distância Euclidiana </li>\n",
    "    <li> 80% do banco de dados como dados de TREINAMENTO </li>\n",
    "    <li> 20% do banco de dados como dados de TESTE </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-sponsorship",
   "metadata": {},
   "source": [
    "#### Acurácia média para 100 rodadas do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "green-crown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média : 85.91%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "size_tests = 100\n",
    "KNN = KNNClassifier('euclidian',7)\n",
    "for index in range(size_tests):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(features, target, test_size=0.2)\n",
    "    KNN.fit(x_train,y_train)\n",
    "    predictions = KNN.predict(x_test)\n",
    "    results.append((predictions,y_test))\n",
    "\n",
    "accuracies = []\n",
    "for r in results:\n",
    "    accuracies.append(accuracy_score(r[0],r[1]))\n",
    "print(\"Acurácia média : {:.2f}%\".format(np.mean(accuracies)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-database",
   "metadata": {},
   "source": [
    "#### Acurácias médias de acerto por classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "coated-proof",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 1.0 : 96.00%\n",
      "Classe 2.0 : 33.33%\n",
      "Classe 3.0 : 100.00%\n",
      "Classe 4.0 : 85.71%\n",
      "Classe 5.0 : 100.00%\n",
      "Classe 6.0 : 100.00%\n"
     ]
    }
   ],
   "source": [
    "classes_all = set(classes)\n",
    "for c in classes_all:\n",
    "    score = []\n",
    "    for r in results:\n",
    "        score.append(accuracy_score_per_class(predictions,y_test,c))\n",
    "    print(\"Classe {:} : {:.2f}%\".format(c,np.mean(score)*100))\n",
    "    score.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-bulletin",
   "metadata": {},
   "source": [
    "#### Matrizes de confusão para o pior e melhor caso dentre as 100 rodadas de treinamente/teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "frequent-flower",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor caso - Acurácia: 97.30%\n",
      "[[30.  0.  0.  0.  0.  0.]\n",
      " [ 0.  6.  0.  1.  0.  0.]\n",
      " [ 0.  0. 15.  0.  0.  0.]\n",
      " [ 0.  0.  0.  7.  0.  0.]\n",
      " [ 0.  0.  0.  0. 13.  0.]\n",
      " [ 1.  0.  0.  0.  0.  1.]]\n",
      "\n",
      "Pior caso - Acurácia : 75.68%\n",
      "[[19.  0.  0.  1.  4.  0.]\n",
      " [ 1.  5.  0.  4.  1.  0.]\n",
      " [ 0.  0. 20.  0.  0.  0.]\n",
      " [ 0.  3.  1.  4.  2.  0.]\n",
      " [ 0.  0.  0.  0.  5.  0.]\n",
      " [ 0.  0.  0.  0.  1.  3.]]\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(results[0][0],results[0][1])\n",
    "higher_value = acc\n",
    "lower_value = acc\n",
    "lower = results[0]\n",
    "higher = results[0]\n",
    "for index in range(1,len(results)):\n",
    "    accuracy = accuracy_score(results[index][0],results[index][1])\n",
    "    if accuracy > higher_value:\n",
    "        higher = results[index]\n",
    "        higher_value = accuracy\n",
    "    if accuracy < lower_value:\n",
    "        lower = results[index]\n",
    "        lower_value = accuracy\n",
    "        \n",
    "print(\"Melhor caso - Acurácia: {:.2f}%\".format(accuracy_score(higher[0],higher[1])*100))\n",
    "print(confusion_matrix(higher[0],higher[1]))\n",
    "print()\n",
    "print(\"Pior caso - Acurácia : {:.2f}%\".format(accuracy_score(lower[0],lower[1])*100))\n",
    "print(confusion_matrix(lower[0],lower[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-error",
   "metadata": {},
   "source": [
    "#### Execução do algoritmo (usando a distância MANHATAN): :\n",
    "\n",
    "<ul>\n",
    "    <li> Utilizando K = 7 </li>\n",
    "    <li> Distância Manhatan </li>\n",
    "    <li> 80% do banco de dados como dados de TREINAMENTO </li>\n",
    "    <li> 20% do banco de dados como dados de TESTE </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-aging",
   "metadata": {},
   "source": [
    "#### Acurácia média para 100 rodadas do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "activated-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média : 94.77%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "size_tests = 100\n",
    "KNN = KNNClassifier('manhatan',7)\n",
    "for index in range(size_tests):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(features, target, test_size=0.2)\n",
    "    KNN.fit(x_train,y_train)\n",
    "    predictions = KNN.predict(x_test)\n",
    "    results.append((predictions,y_test))\n",
    "\n",
    "accuracies = []\n",
    "for r in results:\n",
    "    accuracies.append(accuracy_score(r[0],r[1]))\n",
    "print(\"Acurácia média : {:.2f}%\".format(np.mean(accuracies)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-museum",
   "metadata": {},
   "source": [
    "#### Acurácias médias de acerto por classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "english-tower",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 1.0 : 100.00%\n",
      "Classe 2.0 : 85.71%\n",
      "Classe 3.0 : 100.00%\n",
      "Classe 4.0 : 100.00%\n",
      "Classe 5.0 : 100.00%\n",
      "Classe 6.0 : 100.00%\n"
     ]
    }
   ],
   "source": [
    "classes_all = set(classes)\n",
    "for c in classes_all:\n",
    "    score = []\n",
    "    for r in results:\n",
    "        score.append(accuracy_score_per_class(predictions,y_test,c))\n",
    "    print(\"Classe {:} : {:.2f}%\".format(c,np.mean(score)*100))\n",
    "    score.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-worth",
   "metadata": {},
   "source": [
    "#### Matrizes de confusão para o pior e melhor caso dentre as 100 rodadas de treinamente/teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "solar-italic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor caso - Acurácia: 100.00%\n",
      "[[28.  0.  0.  0.  0.  0.]\n",
      " [ 0. 10.  0.  0.  0.  0.]\n",
      " [ 0.  0. 15.  0.  0.  0.]\n",
      " [ 0.  0.  0.  7.  0.  0.]\n",
      " [ 0.  0.  0.  0. 10.  0.]\n",
      " [ 0.  0.  0.  0.  0.  4.]]\n",
      "\n",
      "Pior caso - Acurácia : 89.19%\n",
      "[[25.  0.  0.  0.  0.  0.]\n",
      " [ 0.  8.  0.  1.  0.  0.]\n",
      " [ 0.  0. 13.  0.  0.  0.]\n",
      " [ 0.  7.  0.  7.  0.  0.]\n",
      " [ 0.  0.  0.  0. 11.  0.]\n",
      " [ 0.  0.  0.  0.  0.  2.]]\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(results[0][0],results[0][1])\n",
    "higher_value = acc\n",
    "lower_value = acc\n",
    "lower = results[0]\n",
    "higher = results[0]\n",
    "for index in range(1,len(results)):\n",
    "    accuracy = accuracy_score(results[index][0],results[index][1])\n",
    "    if accuracy > higher_value:\n",
    "        higher = results[index]\n",
    "        higher_value = accuracy\n",
    "    if accuracy < lower_value:\n",
    "        lower = results[index]\n",
    "        lower_value = accuracy\n",
    "        \n",
    "print(\"Melhor caso - Acurácia: {:.2f}%\".format(accuracy_score(higher[0],higher[1])*100))\n",
    "print(confusion_matrix(higher[0],higher[1]))\n",
    "print()\n",
    "print(\"Pior caso - Acurácia : {:.2f}%\".format(accuracy_score(lower[0],lower[1])*100))\n",
    "print(confusion_matrix(lower[0],lower[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-sunday",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "#### Podemos ver que a distância MANHATAN funciona melhor para esse conjunto de dados do que a distância EUCLIDIANA, pois obtemos uma acurácia média de 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-married",
   "metadata": {},
   "source": [
    "## Parte 2 : Linear Discriminant Analysis\n",
    "### Funcionamento do algoritmo\n",
    "\n",
    "O algoritmo conhecido como LDA (Linear Discriminant Analysis) é um algoritmo que pode ser utilizado tanto para problemas de classificação quanto para reduzir dimensionalidade em problemas com um extenso conjunto de dados. Quando utilizado como classificador, à exemplo da aplicação neste relatório, o objetivo principal do algoritmo é obter N funções discriminantes, sendo N igual ao número de classes no conjunto de dados, onde cada função está associada a uma classe do conjunto de dados. O discriminante com maior valor define a qual classe pertence a amostra analisada. Os passos para execução do algoritmo se encontram logo abaixo:\n",
    "\n",
    "<ol>\n",
    "<li>Recebe uma amostra que ainda não foi classificada.</li>\n",
    "<li>Calcula o vetor médio da matriz de features.</li>\n",
    "<li>Calcula as matrizes de covariância para cada classe usando suas respectivas amostras.</li>\n",
    "<li>Calcula a matriz de espalhamento utilizando as matrizes de covariância.</li>\n",
    "<li>Salva os termos obtidos anteriormente para cada discriminante associado a suas respectivas classes.</li>\n",
    "<li>Para classificar a nova amostra, basta calcular os discriminantes para cada classe usando os termos obtidos no passo 4.O maior discriminantes,que está diretamente associado a uma classe, define a qual classe pertence a nova amostra.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-marking",
   "metadata": {},
   "source": [
    "### Implementacão do classificador \"Linear Discriminant Analysis (LDA)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "french-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA:\n",
    "    def __init__(self,features,target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "    def fit(self):\n",
    "        global_mean = feature_mean(self.features)\n",
    "        class_values = np.sort(np.unique(self.target))\n",
    "        self.class_values = class_values\n",
    "        cov_matrixes = []\n",
    "        for c in class_values:\n",
    "            cov = cov_matrix(self.features,self.target,c,global_mean)\n",
    "            cov_matrixes.append(cov)\n",
    "        self.mean_per_class = []\n",
    "        for c in class_values:\n",
    "            indexes = self.target == c\n",
    "            mean_v = feature_mean(self.features[indexes])\n",
    "            self.mean_per_class.append(mean_v)\n",
    "        self.within = within_classes(self.features,cov_matrixes,self.target)\n",
    "    def predict(self,new_data):\n",
    "        values = []\n",
    "        for idx,c in enumerate(self.class_values):\n",
    "            disc = discrimant(self.mean_per_class[idx],self.within,new_data,self.target,c,len(self.features))\n",
    "            values.append(disc)\n",
    "        return self.class_values[values.index(max(values))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-warning",
   "metadata": {},
   "source": [
    "## Parte 2.1 : Linear Discriminant Analysis(LDA)\n",
    "### Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-tissue",
   "metadata": {},
   "source": [
    "#### Leitura da base \"demartology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "literary-billy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  25  26  27  28  29  30  31  \\\n",
       "0   2   2   0   3   0   0   0   0   1   0  ...   0   0   3   0   0   0   1   \n",
       "1   3   3   3   2   1   0   0   0   1   1  ...   0   0   0   0   0   0   1   \n",
       "2   2   1   2   3   1   3   0   3   0   0  ...   0   2   3   2   0   0   2   \n",
       "3   2   2   2   0   0   0   0   0   3   2  ...   3   0   0   0   0   0   3   \n",
       "4   2   3   2   2   2   2   0   2   0   0  ...   2   3   2   3   0   0   2   \n",
       "\n",
       "   32  33  34  \n",
       "0   0  55   2  \n",
       "1   0   8   1  \n",
       "2   3  26   3  \n",
       "3   0  40   1  \n",
       "4   3  45   3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv(\"./data/dermatology.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-oakland",
   "metadata": {},
   "source": [
    "Converter o dataframe pandas para um objeto do numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "textile-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-animal",
   "metadata": {},
   "source": [
    "#### Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-serial",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Como informado anteriormente, a coluna 33 do banco de dados possui valores inválidos que atrapalham a execução do algoritmo, logo, afim de evitar a remoção da amostras que possuem esse problema, foi adotado a heurística de substituir os valores inválidos,pontos de interrogação,pela mediana da coluna. A mediana foi escolhida por ser menos sensível a outliers se comparada com a média, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "spatial-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:,33] = transform_column(data[:,33])\n",
    "data = data.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-welding",
   "metadata": {},
   "source": [
    "Agora iremos separar o conjunto de dados em uma matriz de features e um array com as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "assured-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[:,:34]\n",
    "target = data[:,34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-breathing",
   "metadata": {},
   "source": [
    "#### Execução do algoritmo :\n",
    "\n",
    "<ul>\n",
    "    <li> 80% do banco de dados como dados de TREINAMENTO. </li>\n",
    "    <li> 20% do banco de dados como dados de TESTE. </li>\n",
    "    <li> Executar o algoritmo 100 vezes e obter a acurácia média. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "relevant-toddler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média : 93.24%\n"
     ]
    }
   ],
   "source": [
    "ac = []\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2,random_state=42)\n",
    "    lda = LDA(X_train,y_train)\n",
    "    lda.fit()\n",
    "    predicts = []\n",
    "    for i in X_test:\n",
    "        predicts.append(lda.predict(i))\n",
    "    count = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == predicts[i]:\n",
    "            count+=1\n",
    "    ac.append(100*count/len(y_test))\n",
    "\n",
    "print(\"Acurácia média : {:.2f}%\".format(np.mean(ac))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
