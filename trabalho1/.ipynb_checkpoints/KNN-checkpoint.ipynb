{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "virgin-slovakia",
   "metadata": {},
   "source": [
    "# Introdução ao Reconhecimento de Padrões, 2020.2, UFC/DETI\n",
    "## Trabalho 1\n",
    "\n",
    "Aluno : Thyago Freitas da Silva <br>\n",
    "Matrícula : 392035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "knowing-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import collections\n",
    "import pandas\n",
    "from random import randrange\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "#from sklearn.datasets import load_iris\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-proof",
   "metadata": {},
   "source": [
    "### Implementacão do classificador \"K Vizinhos mais Proximos (KNN)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "failing-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_p = lambda x,y,p : abs((x-y))**p\n",
    "euclidian = lambda list1,list2: np.sqrt(sum(map(norm_p,list1,list2,[2]*len(list1))))\n",
    "manhatan = lambda list1,list2: sum(map(norm_p,list1,list2,[1]*len(list1)))\n",
    "\n",
    "metrics = {\n",
    "    \"euclidian\" : euclidian,\n",
    "    \"manhatan\" : manhatan\n",
    "}\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, metric=\"euclidian\", n_neighbors=3):\n",
    "        if metric not in metrics:\n",
    "            message = \"invalid metric. the acceptable values are :\"\n",
    "            for k in metrics.keys():\n",
    "                message += \" \" + k\n",
    "            raise Exception(message)\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric_name = metric\n",
    "        self.metric_func = metrics[metric]\n",
    "    def fit(self, x_train,y_train):\n",
    "        if len(x_train) != len(y_train):\n",
    "            raise Exception(\"the size of inputs must be equals\")\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def predict(self,x_test):\n",
    "        distances = []\n",
    "        result = []\n",
    "        for test in x_test:\n",
    "            for index in range(len(self.x_train)):\n",
    "                distance = self.metric_func(self.x_train[index],test)\n",
    "                distances.append((self.y_train[index], distance))\n",
    "            distances = sorted(distances, key = lambda tup : tup[1])\n",
    "            classes = collections.Counter(map(lambda x : x[0], distances[:self.n_neighbors]))\n",
    "            clas = classes.most_common(1)\n",
    "            result.append(clas[0][0])\n",
    "            distances.clear()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-broadcast",
   "metadata": {},
   "source": [
    "### Leitura da base \"demartology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outstanding-basket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 366 entries, 0 to 365\n",
      "Data columns (total 35 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       366 non-null    int64 \n",
      " 1   1       366 non-null    int64 \n",
      " 2   2       366 non-null    int64 \n",
      " 3   3       366 non-null    int64 \n",
      " 4   4       366 non-null    int64 \n",
      " 5   5       366 non-null    int64 \n",
      " 6   6       366 non-null    int64 \n",
      " 7   7       366 non-null    int64 \n",
      " 8   8       366 non-null    int64 \n",
      " 9   9       366 non-null    int64 \n",
      " 10  10      366 non-null    int64 \n",
      " 11  11      366 non-null    int64 \n",
      " 12  12      366 non-null    int64 \n",
      " 13  13      366 non-null    int64 \n",
      " 14  14      366 non-null    int64 \n",
      " 15  15      366 non-null    int64 \n",
      " 16  16      366 non-null    int64 \n",
      " 17  17      366 non-null    int64 \n",
      " 18  18      366 non-null    int64 \n",
      " 19  19      366 non-null    int64 \n",
      " 20  20      366 non-null    int64 \n",
      " 21  21      366 non-null    int64 \n",
      " 22  22      366 non-null    int64 \n",
      " 23  23      366 non-null    int64 \n",
      " 24  24      366 non-null    int64 \n",
      " 25  25      366 non-null    int64 \n",
      " 26  26      366 non-null    int64 \n",
      " 27  27      366 non-null    int64 \n",
      " 28  28      366 non-null    int64 \n",
      " 29  29      366 non-null    int64 \n",
      " 30  30      366 non-null    int64 \n",
      " 31  31      366 non-null    int64 \n",
      " 32  32      366 non-null    int64 \n",
      " 33  33      366 non-null    object\n",
      " 34  34      366 non-null    int64 \n",
      "dtypes: int64(34), object(1)\n",
      "memory usage: 100.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pandas.read_csv(\"./data/dermatology.csv\", header=None)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-logistics",
   "metadata": {},
   "source": [
    "#### Pre-processamento\n",
    "\n",
    "Olhando o conteúdo do arquivo, foi notado que algumas linhas da coluna 33 (band-like infiltrate) apresentam valores marcados com \"?\" que atrapalham o resultado do algoritmo. Para remediar esse problema , decidi trocar os valores faltantes demarcados por \"?\" pela mediana da coluna 33, pois tal medida é menos sensível a outliers se comparado com a média, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confident-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_median(array):\n",
    "    values = []\n",
    "    for v in array:\n",
    "        if v != '?':\n",
    "            v = int(v)\n",
    "            values.append(v)\n",
    "    return np.median(values)\n",
    "\n",
    "median = calc_median(data.iloc[:,33])\n",
    "data.iloc[:,33] = list(map(lambda value: median if value == '?' else value, data.iloc[:,33]))\n",
    "data.iloc[:,33] = data.iloc[:,33].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-record",
   "metadata": {},
   "source": [
    "#### Separar dados em atributos e classes de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "general-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "atribbutes = data.iloc[:,:34]\n",
    "target = data.iloc[:,34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-measurement",
   "metadata": {},
   "source": [
    "#### Separar em bases de teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecological-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data,target,size=0.3):\n",
    "    test_size = int(len(target)*size)\n",
    "    numbers = []\n",
    "    x_train,y_train,x_test,y_test = [],[],[],[]\n",
    "    while len(numbers) != test_size:\n",
    "        v = randrange(len(target))\n",
    "        if v not in numbers:\n",
    "            numbers.append(v)\n",
    "            x_test.append(data.iloc[v,:].values)\n",
    "            y_test.append(target[v])\n",
    "    for i in range(len(data)):\n",
    "        if i not in numbers:\n",
    "            x_train.append(data.iloc[i,:].values)\n",
    "            y_train.append(target[i])\n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n",
    "def accuracy_score(prediction,real_values):\n",
    "    size = len(real_values)\n",
    "    corrects = 0\n",
    "    for index in range(size):\n",
    "        if prediction[index] == real_values[index]:\n",
    "            corrects += 1\n",
    "    return corrects/size\n",
    "\n",
    "def accuracy_score_per_class(prediction,real_values,classe):\n",
    "    size = len(real_values)\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    for index in range(size):\n",
    "        if real_values[index] == classe:\n",
    "            total += 1\n",
    "        if prediction[index] == real_values[index] == classe:\n",
    "            corrects += 1\n",
    "    return corrects/total\n",
    "\n",
    "def confusion_matrix(predict,real_values):\n",
    "    classes = set(real_values)\n",
    "    n_predicts = len(predict)\n",
    "    n_classes = len(classes)\n",
    "    confusion_m = np.zeros((n_classes,n_classes))\n",
    "    for cl in classes:\n",
    "        for index in range(n_predicts):\n",
    "            if real_values[index] == cl:\n",
    "                confusion_m[predict[index]-1,real_values[index]-1] += 1\n",
    "    return confusion_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-anime",
   "metadata": {},
   "source": [
    "#### Taxa média de acerto para 100 rodadas de treinamento/teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "talented-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "size_tests = 100\n",
    "KNN = KNNClassifier('euclidian',3)\n",
    "for index in range(size_tests):\n",
    "    x_train,y_train,x_test,y_test = train_test_split(atribbutes,target,0.3)\n",
    "    KNN.fit(x_train,y_train)\n",
    "    predictions = KNN.predict(x_test)\n",
    "    results.append((predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hidden-inclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.38532110091742\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for r in results:\n",
    "    accuracies.append(accuracy_score(r[0],r[1]))\n",
    "print(np.mean(accuracies)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-database",
   "metadata": {},
   "source": [
    "#### Taxas médias de acerto por classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coated-proof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 97.29729729729729%\n",
      "2 : 71.4285714285714%\n",
      "3 : 100.0%\n",
      "4 : 75.0%\n",
      "5 : 77.77777777777776%\n",
      "6 : 100.0%\n"
     ]
    }
   ],
   "source": [
    "classes = set(target)\n",
    "for c in classes:\n",
    "    score = []\n",
    "    for r in results:\n",
    "        score.append(accuracy_score_per_class(predictions,y_test,c))\n",
    "    print(\"{0} : {1}%\".format(c,np.mean(score)*100))\n",
    "    score.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "narrative-content",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Higher: 93.58%\n",
      "[[34.  0.  0.  0.  0.  0.]\n",
      " [ 0. 14.  0.  1.  2.  0.]\n",
      " [ 0.  0. 26.  0.  0.  0.]\n",
      " [ 0.  1.  0. 13.  1.  0.]\n",
      " [ 0.  0.  0.  2. 12.  0.]\n",
      " [ 0.  0.  0.  0.  0.  3.]]\n",
      "Accurac Lower: 79.82%\n",
      "[[30.  0.  0.  0.  0.  0.]\n",
      " [ 0.  9.  0.  2.  0.  0.]\n",
      " [ 0.  0. 31.  0.  0.  0.]\n",
      " [ 0. 14.  0.  8.  2.  0.]\n",
      " [ 0.  0.  0.  0.  6.  0.]\n",
      " [ 2.  2.  0.  0.  0.  3.]]\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(results[0][0],results[0][1])\n",
    "higher_value = acc\n",
    "lower_value = acc\n",
    "lower = results[0]\n",
    "higher = results[0]\n",
    "for index in range(1,len(results)):\n",
    "    accuracy = accuracy_score(results[index][0],results[index][1])\n",
    "    if accuracy > higher_value:\n",
    "        higher = results[index]\n",
    "        higher_value = accuracy\n",
    "    if accuracy < lower_value:\n",
    "        lower = results[index]\n",
    "        lower_value = accuracy\n",
    "\n",
    "print(\"Accuracy Higher: {:.2f}%\".format(accuracy_score(higher[0],higher[1])*100))\n",
    "print(confusion_matrix(higher[0],higher[1]))\n",
    "print(\"Accurac Lower: {:.2f}%\".format(accuracy_score(lower[0],lower[1])*100))\n",
    "print(confusion_matrix(lower[0],lower[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
