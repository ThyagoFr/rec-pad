{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "virgin-slovakia",
   "metadata": {},
   "source": [
    "# Introdução ao Reconhecimento de Padrões, 2020.2, UFC/DETI\n",
    "## Trabalho 1\n",
    "\n",
    "Aluno : Thyago Freitas da Silva <br>\n",
    "Matrícula : 392035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "knowing-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import collections\n",
    "import pandas\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-theology",
   "metadata": {},
   "source": [
    "### Funções úteis durante o decorrer do relatório"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-timing",
   "metadata": {},
   "source": [
    "#### Calcular mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expanded-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_median(array):\n",
    "    values = []\n",
    "    for v in array:\n",
    "        if v != '?':\n",
    "            v = int(v)\n",
    "            values.append(v)\n",
    "    return np.median(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-silence",
   "metadata": {},
   "source": [
    "#### Normalizar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unknown-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    columns = data.shape[1] - 1 #subtrai 1 para descartar coluna com classes\n",
    "    for c in range(columns):\n",
    "        min_v = np.min(data.iloc[:,c])\n",
    "        max_v = np.max(data.iloc[:,c])\n",
    "        data.iloc[:,c] = data.iloc[:,c].apply(lambda v : (v - min_v)/(max_v - min_v))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-nancy",
   "metadata": {},
   "source": [
    "#### Calcular acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enormous-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(prediction,real_values):\n",
    "    size = len(real_values)\n",
    "    corrects = 0\n",
    "    for index in range(size):\n",
    "        if prediction[index] == real_values[index]:\n",
    "            corrects += 1\n",
    "    return corrects/size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-combining",
   "metadata": {},
   "source": [
    "#### Calcular acurácia por classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "national-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_per_class(prediction,real_values,classe):\n",
    "    size = len(real_values)\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    for index in range(size):\n",
    "        if real_values[index] == classe:\n",
    "            total += 1\n",
    "        if prediction[index] == real_values[index] == classe:\n",
    "            corrects += 1\n",
    "    return corrects/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-adjustment",
   "metadata": {},
   "source": [
    "#### Calcular matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "optimum-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predict,real_values):\n",
    "    classes = set(real_values)\n",
    "    n_predicts = len(predict)\n",
    "    n_classes = len(classes)\n",
    "    confusion_m = np.zeros((n_classes,n_classes))\n",
    "    for cl in classes:\n",
    "        for index in range(n_predicts):\n",
    "            if real_values[index] == cl:\n",
    "                confusion_m[predict[index]-1,real_values[index]-1] += 1\n",
    "    return confusion_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-diamond",
   "metadata": {},
   "source": [
    "#### Separar banco de dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "backed-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data,target,size=0.3):\n",
    "    test_size = int(len(target)*size)\n",
    "    numbers = []\n",
    "    x_train,y_train,x_test,y_test = [],[],[],[]\n",
    "    while len(numbers) != test_size:\n",
    "        v = randrange(len(target))\n",
    "        if v not in numbers:\n",
    "            numbers.append(v)\n",
    "            x_test.append(data.iloc[v,:].values)\n",
    "            y_test.append(target[v])\n",
    "    for i in range(len(data)):\n",
    "        if i not in numbers:\n",
    "            x_train.append(data.iloc[i,:].values)\n",
    "            y_train.append(target[i])\n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-california",
   "metadata": {},
   "source": [
    "## Parte 0 : Banco de dados - Demartology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-ticket",
   "metadata": {},
   "source": [
    "O banco de dados utilizado foi o \"Demartology\" que possui as seguintes características:\n",
    "\n",
    "<ul>\n",
    "<li>O arquivo CSV com os dados possui 35 colunas, sendo que a última coluna representa de forma numérica uma doenção demartológica.</li>\n",
    "<li>A coluna 33 (band-like infiltrate) apresenta valores inválidos e que precisam ser removidos ou processados.</li>\n",
    "<li>Temos 366 amostras no banco de dados.</li>\n",
    "<li>A coluna 34 representa uma doença demartológica de forma numérica(1 à 6), sendo elas :</li>\n",
    "    <ol>\n",
    "        <li>psoriasis</li>\n",
    "        <li>seboreic dermatitis</li>\n",
    "        <li>lichen planus</li>\n",
    "        <li>pityriasis rosea</li>\n",
    "        <li>cronic dermatitis</li>\n",
    "        <li>pityriasis rubra pilaris</li>\n",
    "    </ol>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "urban-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  25  26  27  28  29  30  31  \\\n",
       "0   2   2   0   3   0   0   0   0   1   0  ...   0   0   3   0   0   0   1   \n",
       "1   3   3   3   2   1   0   0   0   1   1  ...   0   0   0   0   0   0   1   \n",
       "2   2   1   2   3   1   3   0   3   0   0  ...   0   2   3   2   0   0   2   \n",
       "3   2   2   2   0   0   0   0   0   3   2  ...   3   0   0   0   0   0   3   \n",
       "4   2   3   2   2   2   2   0   2   0   0  ...   2   3   2   3   0   0   2   \n",
       "\n",
       "   32  33  34  \n",
       "0   0  55   2  \n",
       "1   0   8   1  \n",
       "2   3  26   3  \n",
       "3   0  40   1  \n",
       "4   3  45   3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv(\"./data/dermatology.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-special",
   "metadata": {},
   "source": [
    "## Parte 1 : KNearest Neighbors\n",
    "### Funcionamento do algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-involvement",
   "metadata": {},
   "source": [
    "O algoritmo conhecido como KNN (K-Nearest Neighbors) é um dos muitos algoritmos para classificação, mas que também possui uma versão que pode ser utilizada para regressão, e um dos primeiros a serem apresentados a iniciantes na área de aprendizado de máquina. Seu funcionamento pode ser descrito nas seguintes etapas.\n",
    "\n",
    "<ol>\n",
    "<li>Recebe uma amostra que ainda não foi classificada.</li>\n",
    "<li>Calcula a distância dessa amostra para todas as outras amostras do banco de dados(a métrica utilizada para calcular a distância pode variar com base nos cenários de projeto.).</li>\n",
    "<li>Filtra as K amostras mais próximas da amostra não classificada ainda.</li>\n",
    "<li>Verifica a classe mais frequentes dentre as K amostras filtradas no passo 3.</li>\n",
    "<li>Classifica a amostra do passo 1 como pertencente a classe obtida no passo 4.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-proof",
   "metadata": {},
   "source": [
    "### Implementacão do classificador \"K-Nearest Neighbors (KNN)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "failing-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_p = lambda x,y,p : abs((x-y))**p\n",
    "euclidian = lambda list1,list2: np.sqrt(sum(map(norm_p,list1,list2,[2]*len(list1))))\n",
    "manhatan = lambda list1,list2: sum(map(norm_p,list1,list2,[1]*len(list1)))\n",
    "\n",
    "metrics = {\n",
    "    \"euclidian\" : euclidian,\n",
    "    \"manhatan\" : manhatan\n",
    "}\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, metric=\"euclidian\", n_neighbors=3):\n",
    "        if metric not in metrics:\n",
    "            message = \"invalid metric. the acceptable values are :\"\n",
    "            for k in metrics.keys():\n",
    "                message += \" \" + k\n",
    "            raise Exception(message)\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric_name = metric\n",
    "        self.metric_func = metrics[metric]\n",
    "    def fit(self, x_train,y_train):\n",
    "        if len(x_train) != len(y_train):\n",
    "            raise Exception(\"the size of inputs must be equals\")\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    def predict(self,x_test):\n",
    "        distances = []\n",
    "        result = []\n",
    "        for test in x_test:\n",
    "            for index in range(len(self.x_train)):\n",
    "                distance = self.metric_func(self.x_train[index],test)\n",
    "                distances.append((self.y_train[index], distance))\n",
    "            distances = sorted(distances, key = lambda tup : tup[1])\n",
    "            classes = collections.Counter(map(lambda x : x[0], distances[:self.n_neighbors]))\n",
    "            clas = classes.most_common(1)\n",
    "            result.append(clas[0][0])\n",
    "            distances.clear()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-ambassador",
   "metadata": {},
   "source": [
    "## Parte 1.1 : KNearest Neighbors\n",
    "### Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-broadcast",
   "metadata": {},
   "source": [
    "#### Leitura da base \"demartology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fixed-lithuania",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  25  26  27  28  29  30  31  \\\n",
       "0   2   2   0   3   0   0   0   0   1   0  ...   0   0   3   0   0   0   1   \n",
       "1   3   3   3   2   1   0   0   0   1   1  ...   0   0   0   0   0   0   1   \n",
       "2   2   1   2   3   1   3   0   3   0   0  ...   0   2   3   2   0   0   2   \n",
       "3   2   2   2   0   0   0   0   0   3   2  ...   3   0   0   0   0   0   3   \n",
       "4   2   3   2   2   2   2   0   2   0   0  ...   2   3   2   3   0   0   2   \n",
       "\n",
       "   32  33  34  \n",
       "0   0  55   2  \n",
       "1   0   8   1  \n",
       "2   3  26   3  \n",
       "3   0  40   1  \n",
       "4   3  45   3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv(\"./data/dermatology.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-wonder",
   "metadata": {},
   "source": [
    "#### Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-danish",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Como informado anteriormente, a coluna 33 do banco de dados possui valores inválidos que atrapalham a execução do algoritmo, logo, afim de evitar a remoção da amostras que possuem esse problema, foi adotado a heurística de substituir os valores inválidos,pontos de interrogação,pela mediana da coluna. A mediana foi escolhida por ser menos sensível a outliers se comparada com a média, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "individual-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = calc_median(data.iloc[:,33])\n",
    "data.iloc[:,33] = list(map(lambda value: median if value == '?' else value, data.iloc[:,33]))\n",
    "data.iloc[:,33] = data.iloc[:,33].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-logistics",
   "metadata": {},
   "source": [
    "Outro fator que pode atrapalhar o desempenho do algoritomo é o fato de que as colunas possuem dimensões diferentes,consequentemente valores muito diferentes. Logo, para solucionar esse problema, o banco de dados foi normalizado fazendo com que os valores fiquem entre 0 e 1 para todas as colunas de atributos, fazendo com que todas as colunas tenham o \"mesmo peso\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "necessary-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,:34]\n",
    "classes = data.iloc[:,34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-benchmark",
   "metadata": {},
   "source": [
    "#### Execução do algoritmo :\n",
    "\n",
    "<ul>\n",
    "    <li> Utilizando K = 7 </li>\n",
    "    <li> Distância Euclidiana </li>\n",
    "    <li> 80% do banco de dados como dados de TREINAMENTO </li>\n",
    "    <li> 20% do banco de dados como dados de TESTE </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-sponsorship",
   "metadata": {},
   "source": [
    "#### Acurácia média para 100 rodadas do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "green-crown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média : 86.73%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "size_tests = 100\n",
    "KNN = KNNClassifier('euclidian',7)\n",
    "for index in range(size_tests):\n",
    "    x_train,y_train,x_test,y_test = train_test_split(features,classes,0.2)\n",
    "    KNN.fit(x_train,y_train)\n",
    "    predictions = KNN.predict(x_test)\n",
    "    results.append((predictions,y_test))\n",
    "\n",
    "accuracies = []\n",
    "for r in results:\n",
    "    accuracies.append(accuracy_score(r[0],r[1]))\n",
    "print(\"Acurácia média : {:.2f}%\".format(np.mean(accuracies)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-database",
   "metadata": {},
   "source": [
    "#### Acurácias médias de acerto por classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "coated-proof",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 1 : 100.00%\n",
      "Classe 2 : 66.67%\n",
      "Classe 3 : 100.00%\n",
      "Classe 4 : 50.00%\n",
      "Classe 5 : 83.33%\n",
      "Classe 6 : 100.00%\n"
     ]
    }
   ],
   "source": [
    "classes_all = set(classes)\n",
    "for c in classes_all:\n",
    "    score = []\n",
    "    for r in results:\n",
    "        score.append(accuracy_score_per_class(predictions,y_test,c))\n",
    "    print(\"Classe {:} : {:.2f}%\".format(c,np.mean(score)*100))\n",
    "    score.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-bulletin",
   "metadata": {},
   "source": [
    "#### Matrizes de confusão para o pior e melhor caso dentre as 100 rodadas de treinamente/teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "frequent-flower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor caso - Acurácia: 97.26%\n",
      "[[26.  0.  0.  0.  0.  0.]\n",
      " [ 0.  8.  0.  1.  0.  0.]\n",
      " [ 0.  0. 15.  0.  0.  0.]\n",
      " [ 0.  0.  0.  9.  0.  0.]\n",
      " [ 1.  0.  0.  0.  7.  0.]\n",
      " [ 0.  0.  0.  0.  0.  6.]]\n",
      "\n",
      "Pior caso - Acurácia : 76.71%\n",
      "[[21.  0.  0.  0.  0.  0.]\n",
      " [ 0.  7.  0.  6.  5.  0.]\n",
      " [ 0.  0. 12.  0.  0.  0.]\n",
      " [ 0.  2.  0.  7.  2.  0.]\n",
      " [ 0.  1.  0.  0.  6.  0.]\n",
      " [ 0.  1.  0.  0.  0.  3.]]\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(results[0][0],results[0][1])\n",
    "higher_value = acc\n",
    "lower_value = acc\n",
    "lower = results[0]\n",
    "higher = results[0]\n",
    "for index in range(1,len(results)):\n",
    "    accuracy = accuracy_score(results[index][0],results[index][1])\n",
    "    if accuracy > higher_value:\n",
    "        higher = results[index]\n",
    "        higher_value = accuracy\n",
    "    if accuracy < lower_value:\n",
    "        lower = results[index]\n",
    "        lower_value = accuracy\n",
    "\n",
    "print(\"Melhor caso - Acurácia: {:.2f}%\".format(accuracy_score(higher[0],higher[1])*100))\n",
    "print(confusion_matrix(higher[0],higher[1]))\n",
    "print()\n",
    "print(\"Pior caso - Acurácia : {:.2f}%\".format(accuracy_score(lower[0],lower[1])*100))\n",
    "print(confusion_matrix(lower[0],lower[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-console",
   "metadata": {},
   "source": [
    "## Parte 2 : Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_mean(features):\n",
    "    return np.mean(features, axis = 0)\n",
    "\n",
    "def cov_matrix(features,classes,class_value,mean):\n",
    "    columns = features.shape[1]\n",
    "    rows = features.shape[0]\n",
    "    for c in range(columns):\n",
    "        for r in range(rows):\n",
    "            features[r,c] = mean[c]\n",
    "    n_instances_of_class = np.count_nonzero(classes == class_value)\n",
    "    cov = (n_instances_of_class/rows)*np.dot(np.transpose(features),features)\n",
    "    return features\n",
    "\n",
    "def within_classes(features,cov_matrixes,classes):\n",
    "    dim = features.shape[1]\n",
    "    rows = features.shape[0]\n",
    "    w_c = np.zeros((dim,dim))\n",
    "    values = []\n",
    "    for cov_idx,cov in enumerate(cov_matrixes):\n",
    "        n_instances_of_class = np.count_nonzero(classes == cov_idx)\n",
    "        term = (n_instances_of_class/rows)*cov\n",
    "        values.append(term)\n",
    "    for v in values:\n",
    "        w_c = np.add(w_c,v)\n",
    "    return w_c\n",
    "\n",
    "def discrimant(mean_per_class,within_classes,new_data,classes,class_value,n_features):\n",
    "    count_instances = np.count_nonzero(classes == class_value)\n",
    "    first_term = np.dot(mean_per_class,np.linalg.inv(within_classes))\n",
    "    mul_transpose = np.outer(first_term,new_data)\n",
    "    second_term = np.dot(0.5*first_term,np.transpose(mean_per_class))\n",
    "    return mul_transpose - second_term + np.ln(count_instances/n_features)\n",
    "\n",
    "\n",
    "class LDA:\n",
    "    def __init__(self,features,target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "    def fit(self):\n",
    "        global_mean = feature_mean(self.features)\n",
    "        class_values = np.sort(np.unique(self.target))\n",
    "        self.class_values = class_values\n",
    "        cov_matrixes = []\n",
    "        for c in class_values:\n",
    "            cov = cov_matrix(self.features,self.target,c,global_mean)\n",
    "            cov_matrixes.append(cov)\n",
    "        self.mean_per_class = []\n",
    "        for c in class_values:\n",
    "            indexes = target == c\n",
    "            mean_v = feature_mean(self.features[indexes])\n",
    "            self.mean_per_class.append(mean_v)\n",
    "        self.within = within_classes(self.features,cov_matrixes,self.target)\n",
    "        print(self.within)\n",
    "    def predict(self,new_data):\n",
    "        values = []\n",
    "        for idx,c in enumerate(self.class_values):\n",
    "            disc = discrimant(self.mean_per_class[idx],self.within,new_data,self.target,c,len(self.features))\n",
    "            values.append(disc)\n",
    "        return self.class_values[values.index(min(values))]\n",
    "    \n",
    "data = np.array([[138,76,38.2],\n",
    "                 [140,75,39.2],\n",
    "                 [145,88,38.6],\n",
    "                 [136,89,39.8],\n",
    "                 [129,95,37.9],\n",
    "                 [133,82,82.3],\n",
    "                 [138,73,38.4],\n",
    "                 [110,62,37.1],\n",
    "                 [115,63,37.2],\n",
    "                 [98,62,36.8],\n",
    "                 [120,65,37.0],\n",
    "                 [118,68,37.1],\n",
    "                 [102,58,37.3],\n",
    "                 [106,65,36.9],\n",
    "                 [111,57,37.0]])\n",
    "\n",
    "target = np.array([1,1,1,1,1,1,1,0,0,0,0,0,0,0,0])\n",
    "new_data = np.array([110,62,37])\n",
    "\n",
    "\n",
    "lda = LDA(data,target)\n",
    "lda.fit()\n",
    "#lda.predict(new_data)\n",
    "# print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
