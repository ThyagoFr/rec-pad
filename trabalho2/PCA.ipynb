{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "virgin-slovakia",
   "metadata": {},
   "source": [
    "# Introdução ao Reconhecimento de Padrões, 2020.2, UFC/DETI\n",
    "## Trabalho 2\n",
    "\n",
    "Aluno : Thyago Freitas da Silva <br>\n",
    "Matrícula : 392035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "knowing-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import collections\n",
    "import pandas as pd\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-theology",
   "metadata": {},
   "source": [
    "### Funções úteis durante o decorrer do relatório"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-neutral",
   "metadata": {},
   "source": [
    "#### Calcular média de todas as colunas de uma matriz e subtrair a média das respectivas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "residential-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_median(data):\n",
    "    columns = data.columns.values\n",
    "    for c in columns:\n",
    "        mean = data[c].mean()\n",
    "        data[c] = data[c].apply(lambda value : value - mean)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-indonesia",
   "metadata": {},
   "source": [
    "#### Calcular matriz de covariância de uma matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "after-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cov(data):\n",
    "    return np.cov(data, rowvar = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-liberty",
   "metadata": {},
   "source": [
    "#### Calcular autovalores e autovetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "basic-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eigen_values_and_vectors(data):\n",
    "    return np.linalg.eig(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-timing",
   "metadata": {},
   "source": [
    "#### Calcular mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expanded-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_median(array):\n",
    "    values = []\n",
    "    for v in array:\n",
    "        if v != '?':\n",
    "            v = int(v)\n",
    "            values.append(v)\n",
    "    return np.median(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-silence",
   "metadata": {},
   "source": [
    "#### Normalizar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unknown-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    scaler = StandardScaler()\n",
    "    return pd.DataFrame(scaler.fit_transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-adjustment",
   "metadata": {},
   "source": [
    "#### Encontrar o número Q com base no percentual exigido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "optimum-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseQ(eigen_values,eigen_vectors,percentual):\n",
    "    total = 0\n",
    "    Q = 0\n",
    "    variance = []\n",
    "    for index in range(len(eigen_values)):\n",
    "        value = eigen_values[index]/np.sum(eigen_values)\n",
    "        variance.append(value)\n",
    "    for v in variance:\n",
    "        total += v\n",
    "        Q += 1\n",
    "        if total >= percentual:\n",
    "            break\n",
    "    return Q,variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-california",
   "metadata": {},
   "source": [
    "## Parte 0 : Banco de dados - Demartology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-ticket",
   "metadata": {},
   "source": [
    "O banco de dados utilizado foi o \"Demartology\" que possui as seguintes características:\n",
    "\n",
    "<ul>\n",
    "<li>O arquivo CSV com os dados possui 35 colunas, sendo que a última coluna representa de forma numérica uma doenção demartológica.</li>\n",
    "<li>A coluna 33 (band-like infiltrate) apresenta valores inválidos e que precisam ser removidos ou processados.</li>\n",
    "<li>Temos 366 amostras no banco de dados.</li>\n",
    "<li>A coluna 35 representa uma doença demartológica de forma numérica(1 à 6), sendo elas :</li>\n",
    "    <ol>\n",
    "        <li>psoriasis</li>\n",
    "        <li>seboreic dermatitis</li>\n",
    "        <li>lichen planus</li>\n",
    "        <li>pityriasis rosea</li>\n",
    "        <li>cronic dermatitis</li>\n",
    "        <li>pityriasis rubra pilaris</li>\n",
    "    </ol>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "urban-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  25  26  27  28  29  30  31  \\\n",
       "0   2   2   0   3   0   0   0   0   1   0  ...   0   0   3   0   0   0   1   \n",
       "1   3   3   3   2   1   0   0   0   1   1  ...   0   0   0   0   0   0   1   \n",
       "2   2   1   2   3   1   3   0   3   0   0  ...   0   2   3   2   0   0   2   \n",
       "3   2   2   2   0   0   0   0   0   3   2  ...   3   0   0   0   0   0   3   \n",
       "4   2   3   2   2   2   2   0   2   0   0  ...   2   3   2   3   0   0   2   \n",
       "\n",
       "   32  33  34  \n",
       "0   0  55   2  \n",
       "1   0   8   1  \n",
       "2   3  26   3  \n",
       "3   0  40   1  \n",
       "4   3  45   3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/dermatology.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-special",
   "metadata": {},
   "source": [
    "## Parte 1 : Principal Component Analysis\n",
    "### Funcionamento do algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-involvement",
   "metadata": {},
   "source": [
    "O algoritmo conhecido como Principal Component Analysis, abreviado como PCA, é uma técnica de análise multivariada que costuma ser utilizada para analisar a relação entre features de um conjunto de amostras a fim de detectar uma forma de reduzir a dimensionalidade das amostras através da diminuição da redundância nos dados ,identificando variáveis que possuem grau considerável de correlação e as condensando, com perda mínima de informação, em um conjunto menor de componentes.\n",
    "\n",
    "Abaixo temos os passos necessários para calcular o PCA.\n",
    "\n",
    "<ol>\n",
    "<li>Padronizar features de forma que todas as features sejam transformadas para a mesma ordem de grandeza.</li>\n",
    "<li>Calcular matriz de covariância com base nos dados modificados pelo passo 1.</li>\n",
    "<li>Calcular autovetores e autovalores.</li>\n",
    "<li>Escolher o número Q que representa a quantidade de autovetores.</li>\n",
    "<li>Multiplicar os autovetores escolhidos pela matriz resultante do passo 1.</li>\n",
    "</ol>\n",
    "\n",
    "O artigo ['Feature selection using principal component analysis'](https://ieeexplore.ieee.org/document/5640135) propõe uma heurística para que o PCA faça feature selection, ou seja, seja capaz de designar quais das features do conjunto de dados original podem ser utilizadas sem perda de informação e quais podem ser descartadas. Os passos necessários seguem abaixo:\n",
    "\n",
    "\n",
    "<ol>\n",
    "<li>Ao calcular os autovetores e autovalores, guardar os indexes originais que associam cada autovalor a uma feature do conjunto de dados inicial.</li>\n",
    "<li>Ao selecionar os Q componentes mais importantes, selecionar dentre os indexes guardados no passo 1, quais estão associados aos Q componentes, de forma que cada index indica qual feature do conjunto de dados original deve ser selecionada.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-proof",
   "metadata": {},
   "source": [
    "### Implementacão do Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "failing-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, percentual):\n",
    "        self.percentual = percentual\n",
    "        self.vectors = []\n",
    "        self.Q = 0\n",
    "    def fit_predict(self, data):\n",
    "        cov_matrix = calc_cov(data)\n",
    "        eigenvalues,eigenvectors = calc_eigen_values_and_vectors(cov_matrix)\n",
    "        sorted_index = np.argsort(eigenvalues)[::-1]\n",
    "        sorted_eigenvalue = eigenvalues[sorted_index]\n",
    "        sorted_eigenvectors = eigenvectors[:,sorted_index]\n",
    "        self.q ,self.variance = chooseQ(sorted_eigenvalue,sorted_eigenvectors,self.percentual)\n",
    "        self.vectors = sorted_eigenvectors[:self.q] \n",
    "        self.values = sorted_eigenvalue\n",
    "        self.features_selected = sorted_index[:self.q]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-ambassador",
   "metadata": {},
   "source": [
    "## Parte 1.1 : Principal Component Analysis\n",
    "### Obtendo Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-broadcast",
   "metadata": {},
   "source": [
    "#### Leitura da base \"demartology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fixed-lithuania",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-00dff8208b2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/dermatology.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "data = pandas.read_csv(\"./data/dermatology.csv\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-wonder",
   "metadata": {},
   "source": [
    "#### Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-danish",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Como informado anteriormente, a coluna 33 do banco de dados possui valores inválidos que atrapalham a execução do algoritmo, logo, afim de evitar a remoção da amostras que possuem esse problema, foi adotado a heurística de substituir os valores inválidos,pontos de interrogação,pela mediana da coluna. A mediana foi escolhida por ser menos sensível a outliers se comparada com a média, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = calc_median(data.iloc[:,33])\n",
    "data.iloc[:,33] = list(map(lambda value: median if value == '?' else value, data.iloc[:,33]))\n",
    "data.iloc[:,33] = data.iloc[:,33].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-logistics",
   "metadata": {},
   "source": [
    "Agora basta separar o conjunto de dados em features e as classes reais de cada amostra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = normalize(data.iloc[:,:34])\n",
    "features = normalized.iloc[:,:34]\n",
    "classes = data.iloc[:,34]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-columbia",
   "metadata": {},
   "source": [
    "#### Obtendo o valor Q para um percentual de 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.95)\n",
    "pca.fit_predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-envelope",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pca.q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-democrat",
   "metadata": {},
   "source": [
    "O valor obtido significa que podemos utilizar apenas 3 dimensões com os componentes obtidos, ao invés de utilizar as N dimensões iniciais.Os componentes estão salvos em pca.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-system",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-gross",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_values = []\n",
    "for i in range(len(pca.variance)):\n",
    "    sum_values.append(pca.variance[i])\n",
    "    if len(sum_values) > 1:\n",
    "        sum_values[i] += sum_values[i-1]\n",
    "    \n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.bar(range(1,len(sum_values)+1),sum_values)\n",
    "plt.title(\"Relação entre número de componentes principais e o percentual de variância associado\")\n",
    "plt.xlabel(\"Número de componentes principais\")\n",
    "plt.ylabel(\"Percentual 'explicado' pelos componentes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-edition",
   "metadata": {},
   "source": [
    "Podemos ver que acima de 20 componentes principais, passamos a ter pouco acréscimo no percentual de variância, de forma que ao aumentar o número de componentes principais estariamos aumentando a complexidade sem ganhar de forma significante a capacidade de explicar os dados. Logo, podemos restringir o número de componentes à um número próximo de 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-cathedral",
   "metadata": {},
   "source": [
    "#### Multiplicar o conjunto de dados normalizado pelos componentes encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-bible",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_features_matrix = features.dot(np.transpose(pca.vectors))\n",
    "new_features_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-pipeline",
   "metadata": {},
   "source": [
    "### Comparando resultados do KNN com PCA e sem PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-lease",
   "metadata": {},
   "source": [
    "#### Com PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_features_matrix, classes, test_size=0.2, random_state=1, stratify=classes)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train,y_train)\n",
    "knn.predict(X_test)\n",
    "score = knn.score(X_test, y_test)\n",
    "print(\"Score with PCA : {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-controversy",
   "metadata": {},
   "source": [
    "#### Sem PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, classes, test_size=0.2, random_state=1, stratify=classes)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train,y_train)\n",
    "knn.predict(X_test)\n",
    "score = knn.score(X_test, y_test)\n",
    "print(\"Score without PCA : {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-ozone",
   "metadata": {},
   "source": [
    "Podemos ver que ao aplicar o PCA para extrair features obtivemos um melhor resultado no KNN e graças ao fato de termos diminuido a dimensão do conjunto de dados, também diminuimos a complexidade de cálculos que o classificador precisa realizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-calibration",
   "metadata": {},
   "source": [
    "## Realizando feature selection usando PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-knowing",
   "metadata": {},
   "source": [
    "Dentro da variaveis features_selected, temos acesso as features originais selecionadas pelo PCA ao aplicar a heurística proposta no artigo comentado anteriormente.Logo, podemos usá-las para selecionar apenas as colunas originais necessárias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-killer",
   "metadata": {},
   "source": [
    "#### Com as features selecionadas pelo PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features.iloc[:,pca.features_selected], classes, test_size=0.2, random_state=1, stratify=classes)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train,y_train)\n",
    "knn.predict(X_test)\n",
    "score = knn.score(X_test, y_test)\n",
    "print(\"Score with PCA : {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-billion",
   "metadata": {},
   "source": [
    "#### Sem as colunas selecionadas pelo PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, classes, test_size=0.2, random_state=1, stratify=classes)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 11)\n",
    "knn.fit(X_train,y_train)\n",
    "knn.predict(X_test)\n",
    "score = knn.score(X_test, y_test)\n",
    "print(\"Score without PCA : {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-terror",
   "metadata": {},
   "source": [
    "Podemos ver que ao aplicar o PCA para selecionar features obtivemos um resultado aproximadamente igual ao KNN usando todas as features do conjunto de dados. Dessa forma, temos que diminuir a dimensionalidade do conjunto de dados não afeta o resultado do classificador, porém melhora o desempenho com relação a velocidade,pois trabalhamos com uma matriz com dimensões muito menores que a matriz original,diminuindo assim a quantidade de operações que devem ser realizadas pelo algoritmo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
